spring:
  application:
    name: network-conversion-server

  cloud:
    aws:
      endpoint: http://localhost:19000
      region:
        static: test
      bucket: ws-bucket
      credentials:
        access-key: s3username
        secret-key: s3password
    function:
      definition: consumeCaseImportStart;consumeNetworkExportStart;consumeCaseExportStart
    stream:
      bindings:
        publishCaseImportStart-out-0:
          destination: ${powsybl-ws.rabbitmq.destination.prefix:}case.import.start
        publishCaseImportSucceeded-out-0:
          destination: ${powsybl-ws.rabbitmq.destination.prefix:}case.import.succeeded
        consumeCaseImportStart-in-0:
          destination: ${powsybl-ws.rabbitmq.destination.prefix:}case.import.start
          group: importGroup
          consumer:
            concurrency: 2 # pay attention to max-concurrent-import-export parameter
            max-attempts: 1
        publishNetworkExportStart-out-0:
          destination: ${powsybl-ws.rabbitmq.destination.prefix:}network.export.start
        publishNetworkExportSucceeded-out-0:
          destination: ${powsybl-ws.rabbitmq.destination.prefix:}network.export.succeeded
        consumeNetworkExportStart-in-0:
          destination: ${powsybl-ws.rabbitmq.destination.prefix:}network.export.start
          group: exportGroup
          consumer:
            concurrency: 2
            max-attempts: 1
        publishCaseExportStart-out-0:
          destination: ${powsybl-ws.rabbitmq.destination.prefix:}case.export.start
        publishCaseExportSucceeded-out-0:
          destination: ${powsybl-ws.rabbitmq.destination.prefix:}case.export.succeeded
        consumeCaseExportStart-in-0:
          destination: ${powsybl-ws.rabbitmq.destination.prefix:}case.export.start
          group: exportGroup
          consumer:
            concurrency: 2
            max-attempts: 1
      output-bindings: publishCaseImportStart-out-0;publishCaseImportSucceeded-out-0;publishNetworkExportStart-out-0;publishNetworkExportSucceeded-out-0;publishCaseExportStart-out-0;publishCaseExportSucceeded-out-0
      rabbit:
        bindings:
          consumeCaseImportStart-in-0:
            consumer:
              auto-bind-dlq: true
              dead-letter-exchange: ${powsybl-ws.rabbitmq.destination.prefix:}case.import.start.dlx
              dead-letter-queue-name: ${powsybl-ws.rabbitmq.destination.prefix:}case.import.start.dlx.dlq
              dead-letter-exchange-type: topic
              quorum:
                enabled: true
                delivery-limit: 2
          consumeNetworkExportStart-in-0:
            consumer:
              auto-bind-dlq: true
              dead-letter-exchange: ${powsybl-ws.rabbitmq.destination.prefix:}network.export.start.dlx
              dead-letter-queue-name: ${powsybl-ws.rabbitmq.destination.prefix:}network.export.start.dlx.dlq
              dead-letter-exchange-type: topic
              quorum:
                enabled: true
                delivery-limit: 2
          consumeCaseExportStart-in-0:
            consumer:
              auto-bind-dlq: true
              dead-letter-exchange: ${powsybl-ws.rabbitmq.destination.prefix:}case.export.start.dlx
              dead-letter-queue-name: ${powsybl-ws.rabbitmq.destination.prefix:}case.export.start.dlx.dlq
              dead-letter-exchange-type: topic
              quorum:
                enabled: true
                delivery-limit: 2

powsybl:
  services:
    network-store-server:
      preloading-strategy: COLLECTION

management:
  health:
    solr:
      enabled: false

s3:
  bucket: ws-bucket
  login: s3username
  password: s3password
  subpath:
    prefix: "export/"

export-subpath: "network-exports"

# maximum concurrent network import/export
# to avoid out of memory issues
# WARNING: pay attention for imports, that spring.cloud.stream.bindings.consumeCaseImportStart-in-0.consumer.concurrency
# is consistent with this parameter value
max-concurrent-import-export: 2
